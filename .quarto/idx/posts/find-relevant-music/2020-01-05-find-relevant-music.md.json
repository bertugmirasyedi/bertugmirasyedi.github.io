{"title":"A Simple Way to Find Relevant Music on Spotify","markdown":{"yaml":{"title":"A Simple Way to Find Relevant Music on Spotify","description":"Creating a Playlist Sorter Using Python and Spotify API","date":"2022-08-09","image":"spotify.jpg","categories":["python","spotify","recommender systems"]},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n![](spotify.jpg)\n\n*Time to read: 10 minutes*\n\n- [Introduction](#introduction)\n- [Background](#background)\n- [Methodology](#methodology)\n- [Results](#results)\n- [Discussion](#discussion)\n\n\nListening to music is, like most of the people, one of my favourite things to do. It makes one to experience all kinds of emotions and commuting in Istanbul a much less dreadful journey. But another aspect of the music which I equally love is discovering it and today I will talk about my Python script that help me achieve this.\n\nThe way I will discover new music is through playlists. Using Spotify API, the script will search playlists with given keyword and sort them by the most song overlaps with songs that I have already liked. Even though it does not feature any advanced algorithms; it is simple, does not require any personal data of others and the results were effective for me.\n\n## Background\n\n >A recommender system, or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine), is a subclass of information filtering system that provide suggestions for items that are most pertinent to a particular user. Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read. Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer. [^1]\n\nSo basically, a recommender system uses past behaviour or tastes of people (**collaborative filtering**) or inherent features of things (**content-based**) to recommend new items for users. To give content-based recommendations, firstly, items in which we are interested recommending should have preselected and/or user generated properties. Secondly, users must rate enough of these items so that we can try to understand what properties each user favors. [Music Genome Project](https://www.pandora.com/about/mgp) of Pandora[^3] can be given as an example for this method. Content-based approaches has the advantage of relevancy. Provided the classification of items is done properly, content-based recommendations will almost always be relevant. However, the recommendations are also likely to be \"too similar\" to what the user has already liked; in other words less *serendipitous* and they omit the context[^2]. Let's say there are two books about the same subject and while one of them is supportive of the topic, other one is against it. Content-based recommendation has no method to differentiate this aspect of items.\n\n<figure>\n<p align=\"center\">\n<img src=\"images/mgp.png\" alt=\"mpg\" width=\"450\" height=\"450\"/>\n</p>\n<figcaption align = \"center\"><b>Figure 1.</b><i> Music Genome Project Flowchart</i>\n</figcaption>\n</figure>\n\nRecommendations using collaborative filtering mostly overcomes these drawbacks. Users that have similar tastes can recommend each other the items that neither could find another way. Also it is more probably that similar users like an item in the same context. There are two ways of collaborative filtering: **item-based** and **user-based**. *Item-based collaborative filtering* is closer content-based methods in theory because they both use item similarity to recommend an item. However, whereas content-based recommendation uses their content to measure similarity, item-based collaborative filtering utilizes the taste of users to determine similarity. If several users rate such items in a similar fashion, they are likely to be similar too. *User-based collaborative filtering*, in some cases named as neighborhood-based collaborative filtering, purely based on the proximity of user tastes. Algorithms such as k-Nearest-Neighbors, finds the shortest distance between users by their ratings of same items. Once the closest neighbors are found, their highly rated but unseen to other neighbor items are recommended.\n\n## Methodology\n\nIn this part I will show and explain my method of recommendation with snippets from my Python script. All of the code will be available at my [GitHub](https://www.github.com/bertugmirasyedi) page. \nThe basic algorithm is shown in the Figure 2.\n\n<figure>\n<p align=\"center\">\n<img src=\"images/flowchart.png\" alt=\"flowchart\" width=\"550\" height=\"750\"/>\n</p>\n<figcaption align = \"center\"><b>Figure 2.</b><i> Flowchart of the Python Script</i>\n</figcaption>\n</figure>\n\nBecause I will use Spotify Web API, to access endpoints faster and respect the rate limits, it is better to use a Python wrapper. So my communication with API will be handled by [Spotipy](https://spotipy.readthedocs.io/en/master/). Let's start with importing the required modules.\n\n```python\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth     #Spotipy Authentication Module\nimport time     #To track time\nimport os       #We need os to get environment variables\n```\n\nFirst, we need to set a Spotipy client with credentials and scope.\n\n```python\nscope = [\"user-library-read\",\n         \"user-read-playback-state\",\n         \"user-modify-playback-state\",\n         \"playlist-modify-public\"]\n\nauth_manager = SpotifyOAuth(scope=scope, \n                            redirect_uri=\"http://localhost:8080\", \n                            show_dialog=True)\n\nsp = spotipy.Spotify(auth_manager=auth_manager)\n```\n\n`SpotifyOAuth` here is expecting two variables namely `SPOTIPY_CLIENT_ID` and `SPOTIPY_CLIENT_SECRET` to authenticate our client. I have added them as environment variables.\n\nThe spotipy client is set and ready to access Spotify API. The script asks for an input as a query for searching playlists. I have used genres as query, since they are most likely to have relevant songs in them. The aim is to find playlists with the most overlap with my \"Liked Songs\", with minimal search.\n\n```python\nquery = input(\"Search for playlists: \")\nstart_time = time.time()\n\nplaylists = list()\noffset = 0\nend_offset = 150\nfor offset in range(0, (end_offset + 1), 50):\n    playlists.append(sp.search(query, 50, type=\"playlist\", offset=offset))\n    print((offset + 50), \"playlists added.\\n\")\n```\n\nThe reason for the increment of 50 is due to Spotify API's restriction of the number of items that can be searched in one go to 50. Now we have `playlists` object as JSON response from the API.\n\nNext, I will create a `tracks_response` variable that will contain all songs IDs of the playlists.\n\n```python\ntracks_response = list()\nprint(\"Creating tracks_response.\\n\")\nfor page in range(len(playlists)):\n    for p in range(len(playlists[page][\"playlists\"][\"items\"])):\n        placeholder_tracks_response = list()\n        current_playlist_track_count = sp.playlist_tracks(playlists[page][\"playlists\"][\"items\"][p][\"id\"])[\"total\"]\n        if current_playlist_track_count < 100:\n            tracks_response.append(sp.playlist_items(playlists[page][\"playlists\"][\"items\"][p][\"id\"], \n                                                fields=\"items(track(id))\"))\n        else:\n            offset = 0\n            for i in range(0, current_playlist_track_count, 100):\n                placeholder_tracks_response.append(sp.playlist_items(playlists[page][\"playlists\"][\"items\"][p][\"id\"], \n                                                fields=\"items(track(id))\", offset=offset))\n                offset += 100\n            all_placeholders_together = list()\n            for k in range(len(placeholder_tracks_response)):\n                all_placeholders_together.append(placeholder_tracks_response[k][\"items\"])\n            all_placeholders_together = dict(items = all_placeholders_together)\n            tracks_response.append(all_placeholders_together)\n```\nThis part of the script basically goes through the `playlists` item by item and adds the song IDs to `tracks_response`. Since the API can reach only 100 items at once, the script checks for the number of songs. If it is greater than 100, script adds the IDs by parts of 100 items.\n\nNow we have a list object that has all of the songs IDs of each playlist. It is time to compare the tracks of these playlists with my 'Liked Songs'. We will create a `results` list and add a `True` for each match; otherwise a `False`.\n\n```python\nresults = list()\nfor i in range(len(singleLayerTracksResponse)):\n    tracklist_contains_songs = list()\n    if None in singleLayerTracksResponse[i]:\n        while (None in singleLayerTracksResponse[i]) is True:\n            singleLayerTracksResponse[i][singleLayerTracksResponse[i].index(None)] = \"4cOdK2wGLETKBW3PvgPWqT\"\n    if len(singleLayerTracksResponse[i]) <= 50:\n        tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i]))\n    else:\n        page, remainder = divmod(len(singleLayerTracksResponse[i]), 50)\n        offset = 0\n        if remainder == 0:\n            for j in range(page):\n                tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + 50)]))\n                offset += 50\n        else:\n            offset = 0\n            for j in range(page):\n                tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + 50)]))\n                offset += 50\n            tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + remainder)]))\n    results.append(tracklist_contains_songs)\n```\nThere are two important points in this part of the script. First of all, there could be local songs in these playlists and they don't have a unique song ID. Therefore, the script adds a [dummy song](https://www.youtube.com/watch?v=dQw4w9WgXcQ) in place of NoneType object, which the API can't handle. Second point, to reduce the load on the API and to reduce the chance of being rate limited, the script checks the track overlap with 50 item batches. When I first wrote the script, it didn't utilize this and as a result, it was rate limited. This simple trick also *reduced the total runtime by 65%*.\n\nContinuing, this part counts the number of `True`s and stores them in `songOverlaps`\n\n```python\nsongOverlaps = list()\nfor plist in range(len(results)):\n    songCounter = 0\n    if len(results[plist]) == 1:\n        songCounter = results[plist].count(True)\n    else:\n        for p in range(len(results[plist])):\n            songCounter += results[plist][p].count(True)\n    songOverlaps.append(songCounter)\n```\n\nAfter that comes the sorting of playlists from the most overlapping to least and storing their original indice in `mostOverlapPlaylists_indices`.\n\n```python\nsongOverlaps_original = songOverlaps.copy()\nsongOverlaps_sorted = songOverlaps.copy()\nsongOverlaps_sorted.sort(reverse=1)\nmostOverlapsPlaylists_indices = list()\nfor x in range(0, 6):\n    mostOverlapsPlaylists_indices.append(songOverlaps.index(songOverlaps_sorted[x]))\n    songOverlaps[songOverlaps.index(songOverlaps_sorted[x])] = 0\n```\n\nCollect all of the songs in the overlapping playlists and store them in `overlapsTrackResponse`.\n\n```python\noverlapsTrackResponse = list()\nfor x in mostOverlapsPlaylists_indices:\n    for y in range(len(singleLayerTracksResponse[x])):\n        overlapsTrackResponse.append(singleLayerTracksResponse[x][y])\n```\n\nCheck for duplicates in `overlapsTrackResponse` and if it is in at least `overlapThreshold` number of playlists, add that song ID to `mostOverlapsSongs`. We first convert `mostOverlapsSongs` to a `set` to remove duplicates and to a `list` again for easier manipulation.\n\n```python\nmostOverlapsSongs = list()\noverlapThreshold = 3\nfor x in overlapsTrackResponse:\n    if overlapsTrackResponse.count(x) >= overlapThreshold:  \n        mostOverlapsSongs.append(x)\nmostOverlapsSongs = set(mostOverlapsSongs)\nmostOverlapsSongs = list(mostOverlapsSongs)\n```\n\nAnd lastly, the script will end the timer and store the elapsed time in minutes to `runtimePerMin` and create a playlist with song IDs in `mostOverlapsSongs`.\n\n```python\nend_time = time.time()\nruntimePerMin = int((end_time - start_time)/60)\n\nsp.user_playlist_create(username, name=\"Overlapping Songs from Nearest {} Playlists for Query '{}'\".format(len(mostOverlapsPlaylists_indices), query), description=\"Seed Playlists: {} - Run Time: {} Minutes - Overlap Threshold: {} - Liked Songs: \".format((end_offset + 50), runtimePerMin, overlapThreshold))\nlast_playlist = sp.user_playlists(username, 1, 0)\nsp.playlist_add_items(last_playlist[\"items\"][0][\"id\"], mostOverlapsSongs[0:100])\n```\n## Results\n\nThe script created a playlist with recommended songs from a given query; now what? We have to measure its performance. The performance of the model has to be obviously based on the number of liked new songs from the generated playlist. Therefore, higher the **number of seed playlists** higher the probability of catching a playlist with high overlap right? We set `end_offset` to 10000 and hit enter. However, this would be both time consuming (**Runtime**) and put a heavy load on the Spotify API; thus, runs the risk of being rate limited. I've imagined the scenario that if I were to use this algorithm in the production, what would be my KPI and have settled on **Number of New Likes per Minute**.\n\n<figure>\n<p align=\"center\">\n<img src=\"images/comparison1.png\" alt=\"mpg\" width=\"600\" height=\"600\"/>\n</p>\n</figure>\n\nThis graph shows *New Likes* and the *Number of Seed Playlists* in each experiment. All of the experiments used the same query for genre and I have listened to all of the songs in the playlists. While excluding the ones that are already in my library, I have counted the songs which I liked.\n\n<figure>\n<p align=\"center\">\n<img src=\"images/comparison2.png\" alt=\"mpg\" width=\"600\" height=\"600\"/>\n</p>\n</figure>\n\nThis figure, on the other hand, shows the *Total Number of Songs in Each Playlist* and our KPI or *Number of New Likes per Minute* which is calculated by dividing new likes by runtime.\n\nFrom both of the graphs, we can see that after 200 seed playlists, there are diminishing returns. New likes stays constant of and consequently, KPI decreases. One could argue that Experiment No. 2 has the highest KPI and therefore, it should be selected for the model. However, it generates low count of songs. I think a playlist with song count between 70 and 100 is better. Also greater seed has increased probability of finding more similar playlists.\n\n## Discussion\n\nI think this was great learning experience for me and turned out nicer that I at first expected. Even though it doesn't use any sophisticated algorithms, recommendations were mostly satisfying. It has to be said that the performance of my model depends a couple of variable, some of which I cannot control. For example, how much a user is invested in a genre is very important. If I have only 5 songs in my library for a target genre, my expectations would have to be low.\n\nThere three main controlling variables that changes the outcome of playlists: **number of seed playlists**, **how many of the most overlapping playlists we take into consideration**, and **overlap threshold**. They control how many songs will be in the generated playlist and a high overlap threshold tends to favor more popular songs, obviously. I manually tinkered with them to make song count between 70 and 100 in my experiments but in the future maybe I can add an automation of this. **For now thanks for reading and see you next time!**\n\n[^1]: [Recommender System Entry on Wikipedia](https://en.wikipedia.org/wiki/Recommender_system#Multi-criteria_recommender_systems)\n[^2]: [U. Shardanand, P. Maes, \"Social Information Filtering: Algorithms for Automating \"Word of Mouth\"\" in CHI ’95: Proceedings of the SIGCHI Conference on Human factors in Computing Systems (ACM Press/Addison-Wesley Publishing Co., New York, NY, 1995), pp. 210–217](https://dl.acm.org/doi/pdf/10.1145/223904.223931)\n[^3]: [Pandora Media LLC, \"Consumer item matching method and system\",  U.S. Patent US7003515B1, May 16, 2002\"](https://patents.google.com/patent/US7003515B1/en)"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"2020-01-05-find-relevant-music.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","theme":"flatly","title-block-banner":true,"title":"A Simple Way to Find Relevant Music on Spotify","description":"Creating a Playlist Sorter Using Python and Spotify API","date":"2022-08-09","image":"spotify.jpg","categories":["python","spotify","recommender systems"]},"extensions":{"book":{"multiFile":true}}}}}