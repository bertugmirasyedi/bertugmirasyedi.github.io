[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Homepage",
    "section": "",
    "text": "Book Sales Forecasting: Comparison of Different Models Part 1\n\n\n\n\n\n\n\npython\n\n\ntime series forecasting\n\n\nxgboost\n\n\narima\n\n\n\n\nFrom Classical Statistical Models to XGBoost\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\nBook Sales Forecasting: Comparison of Different Models Part 2\n\n\n\n\n\n\n\npython\n\n\ntime series forecasting\n\n\ntensorflow\n\n\noptuna\n\n\nhyperparameter tuning\n\n\n\n\nDeep Learning Models\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\nA Simple Way to Find Relevant Music on Spotify\n\n\n\n\n\n\n\npython\n\n\nspotify\n\n\nrecommender systems\n\n\n\n\nCreating a Playlist Sorter Using Python and Spotify API\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Bertuğ Mirasyedi, from Istanbul, Turkey. On this blog, I will share my data science learning journey with projects that I find interesting. Occasionally the posts could include about multi-criteria decision analysis too - and maybe mathematical optimization.\nI’m actually a mechanical engineer by training; however, inference from data and trying to make optimal decisions has always fascinated me. I have started learning about data science and specifically about machine learning with the first Coronavirus lockdowns as a hobby. I have successfully finished Google’s Machine Learning Crash Course and that has laid a solid foundation for me.\nEven though I did a few self projects earlier, now I want to fully concentrate on my data science skills and thought that creating a blog about these projects would help me to see my progress (and could serve others as a tutorial)."
  },
  {
    "objectID": "posts/book-forecasting/index.html",
    "href": "posts/book-forecasting/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/find-relevant-music/index.html",
    "href": "posts/find-relevant-music/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "",
    "text": "Time to read: 10 minutes"
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#introduction",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#introduction",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "Introduction",
    "text": "Introduction\nListening to music is, like most of the people, one of my favourite things to do. It makes one to experience all kinds of emotions and commuting in Istanbul a much less dreadful journey. But another aspect of the music which I equally love is discovering it and today I will talk about my Python script that help me achieve this.\nThe way I will discover new music is through playlists. Using Spotify API, the script will search playlists with given keyword and sort them by the most song overlaps with songs that I have already liked. Even though it does not feature any advanced algorithms; it is simple, does not require any personal data of others and the results were effective for me."
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#background",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#background",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "Background",
    "text": "Background\n\nA recommender system, or a recommendation system (sometimes replacing ‘system’ with a synonym such as platform or engine), is a subclass of information filtering system that provide suggestions for items that are most pertinent to a particular user. Typically, the suggestions refer to various decision-making processes, such as what product to purchase, what music to listen to, or what online news to read. Recommender systems are particularly useful when an individual needs to choose an item from a potentially overwhelming number of items that a service may offer. 1\n\nSo basically, a recommender system uses past behaviour or tastes of people (collaborative filtering) or inherent features of things (content-based) to recommend new items for users. To give content-based recommendations, firstly, items in which we are interested recommending should have preselected and/or user generated properties. Secondly, users must rate enough of these items so that we can try to understand what properties each user favors. Music Genome Project of Pandora2 can be given as an example for this method. Content-based approaches has the advantage of relevancy. Provided the classification of items is done properly, content-based recommendations will almost always be relevant. However, the recommendations are also likely to be “too similar” to what the user has already liked; in other words less serendipitous and they omit the context3. Let’s say there are two books about the same subject and while one of them is supportive of the topic, other one is against it. Content-based recommendation has no method to differentiate this aspect of items.\n\n\n\n\n\nFigure 1. Music Genome Project Flowchart\n\n\nRecommendations using collaborative filtering mostly overcomes these drawbacks. Users that have similar tastes can recommend each other the items that neither could find another way. Also it is more probably that similar users like an item in the same context. There are two ways of collaborative filtering: item-based and user-based. Item-based collaborative filtering is closer content-based methods in theory because they both use item similarity to recommend an item. However, whereas content-based recommendation uses their content to measure similarity, item-based collaborative filtering utilizes the taste of users to determine similarity. If several users rate such items in a similar fashion, they are likely to be similar too. User-based collaborative filtering, in some cases named as neighborhood-based collaborative filtering, purely based on the proximity of user tastes. Algorithms such as k-Nearest-Neighbors, finds the shortest distance between users by their ratings of same items. Once the closest neighbors are found, their highly rated but unseen to other neighbor items are recommended."
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#methodology",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#methodology",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "Methodology",
    "text": "Methodology\nIn this part I will show and explain my method of recommendation with snippets from my Python script. All of the code will be available at my GitHub page. The basic algorithm is shown in the Figure 2.\n\n\n\n\n\nFigure 2. Flowchart of the Python Script\n\n\nBecause I will use Spotify Web API, to access endpoints faster and respect the rate limits, it is better to use a Python wrapper. So my communication with API will be handled by Spotipy. Let’s start with importing the required modules.\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth     #Spotipy Authentication Module\nimport time     #To track time\nimport os       #We need os to get environment variables\nFirst, we need to set a Spotipy client with credentials and scope.\nscope = [\"user-library-read\",\n         \"user-read-playback-state\",\n         \"user-modify-playback-state\",\n         \"playlist-modify-public\"]\n\nauth_manager = SpotifyOAuth(scope=scope, \n                            redirect_uri=\"http://localhost:8080\", \n                            show_dialog=True)\n\nsp = spotipy.Spotify(auth_manager=auth_manager)\nSpotifyOAuth here is expecting two variables namely SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET to authenticate our client. I have added them as environment variables.\nThe spotipy client is set and ready to access Spotify API. The script asks for an input as a query for searching playlists. I have used genres as query, since they are most likely to have relevant songs in them. The aim is to find playlists with the most overlap with my “Liked Songs”, with minimal search.\nquery = input(\"Search for playlists: \")\nstart_time = time.time()\n\nplaylists = list()\noffset = 0\nend_offset = 150\nfor offset in range(0, (end_offset + 1), 50):\n    playlists.append(sp.search(query, 50, type=\"playlist\", offset=offset))\n    print((offset + 50), \"playlists added.\\n\")\nThe reason for the increment of 50 is due to Spotify API’s restriction of the number of items that can be searched in one go to 50. Now we have playlists object as JSON response from the API.\nNext, I will create a tracks_response variable that will contain all songs IDs of the playlists.\ntracks_response = list()\nprint(\"Creating tracks_response.\\n\")\nfor page in range(len(playlists)):\n    for p in range(len(playlists[page][\"playlists\"][\"items\"])):\n        placeholder_tracks_response = list()\n        current_playlist_track_count = sp.playlist_tracks(playlists[page][\"playlists\"][\"items\"][p][\"id\"])[\"total\"]\n        if current_playlist_track_count < 100:\n            tracks_response.append(sp.playlist_items(playlists[page][\"playlists\"][\"items\"][p][\"id\"], \n                                                fields=\"items(track(id))\"))\n        else:\n            offset = 0\n            for i in range(0, current_playlist_track_count, 100):\n                placeholder_tracks_response.append(sp.playlist_items(playlists[page][\"playlists\"][\"items\"][p][\"id\"], \n                                                fields=\"items(track(id))\", offset=offset))\n                offset += 100\n            all_placeholders_together = list()\n            for k in range(len(placeholder_tracks_response)):\n                all_placeholders_together.append(placeholder_tracks_response[k][\"items\"])\n            all_placeholders_together = dict(items = all_placeholders_together)\n            tracks_response.append(all_placeholders_together)\nThis part of the script basically goes through the playlists item by item and adds the song IDs to tracks_response. Since the API can reach only 100 items at once, the script checks for the number of songs. If it is greater than 100, script adds the IDs by parts of 100 items.\nNow we have a list object that has all of the songs IDs of each playlist. It is time to compare the tracks of these playlists with my ‘Liked Songs’. We will create a results list and add a True for each match; otherwise a False.\nresults = list()\nfor i in range(len(singleLayerTracksResponse)):\n    tracklist_contains_songs = list()\n    if None in singleLayerTracksResponse[i]:\n        while (None in singleLayerTracksResponse[i]) is True:\n            singleLayerTracksResponse[i][singleLayerTracksResponse[i].index(None)] = \"4cOdK2wGLETKBW3PvgPWqT\"\n    if len(singleLayerTracksResponse[i]) <= 50:\n        tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i]))\n    else:\n        page, remainder = divmod(len(singleLayerTracksResponse[i]), 50)\n        offset = 0\n        if remainder == 0:\n            for j in range(page):\n                tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + 50)]))\n                offset += 50\n        else:\n            offset = 0\n            for j in range(page):\n                tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + 50)]))\n                offset += 50\n            tracklist_contains_songs.append(sp.current_user_saved_tracks_contains(singleLayerTracksResponse[i][offset:(offset + remainder)]))\n    results.append(tracklist_contains_songs)\nThere are two important points in this part of the script. First of all, there could be local songs in these playlists and they don’t have a unique song ID. Therefore, the script adds a dummy song in place of NoneType object, which the API can’t handle. Second point, to reduce the load on the API and to reduce the chance of being rate limited, the script checks the track overlap with 50 item batches. When I first wrote the script, it didn’t utilize this and as a result, it was rate limited. This simple trick also reduced the total runtime by 65%.\nContinuing, this part counts the number of Trues and stores them in songOverlaps\nsongOverlaps = list()\nfor plist in range(len(results)):\n    songCounter = 0\n    if len(results[plist]) == 1:\n        songCounter = results[plist].count(True)\n    else:\n        for p in range(len(results[plist])):\n            songCounter += results[plist][p].count(True)\n    songOverlaps.append(songCounter)\nAfter that comes the sorting of playlists from the most overlapping to least and storing their original indice in mostOverlapPlaylists_indices.\nsongOverlaps_original = songOverlaps.copy()\nsongOverlaps_sorted = songOverlaps.copy()\nsongOverlaps_sorted.sort(reverse=1)\nmostOverlapsPlaylists_indices = list()\nfor x in range(0, 6):\n    mostOverlapsPlaylists_indices.append(songOverlaps.index(songOverlaps_sorted[x]))\n    songOverlaps[songOverlaps.index(songOverlaps_sorted[x])] = 0\nCollect all of the songs in the overlapping playlists and store them in overlapsTrackResponse.\noverlapsTrackResponse = list()\nfor x in mostOverlapsPlaylists_indices:\n    for y in range(len(singleLayerTracksResponse[x])):\n        overlapsTrackResponse.append(singleLayerTracksResponse[x][y])\nCheck for duplicates in overlapsTrackResponse and if it is in at least overlapThreshold number of playlists, add that song ID to mostOverlapsSongs. We first convert mostOverlapsSongs to a set to remove duplicates and to a list again for easier manipulation.\nmostOverlapsSongs = list()\noverlapThreshold = 3\nfor x in overlapsTrackResponse:\n    if overlapsTrackResponse.count(x) >= overlapThreshold:  \n        mostOverlapsSongs.append(x)\nmostOverlapsSongs = set(mostOverlapsSongs)\nmostOverlapsSongs = list(mostOverlapsSongs)\nAnd lastly, the script will end the timer and store the elapsed time in minutes to runtimePerMin and create a playlist with song IDs in mostOverlapsSongs.\nend_time = time.time()\nruntimePerMin = int((end_time - start_time)/60)\n\nsp.user_playlist_create(username, name=\"Overlapping Songs from Nearest {} Playlists for Query '{}'\".format(len(mostOverlapsPlaylists_indices), query), description=\"Seed Playlists: {} - Run Time: {} Minutes - Overlap Threshold: {} - Liked Songs: \".format((end_offset + 50), runtimePerMin, overlapThreshold))\nlast_playlist = sp.user_playlists(username, 1, 0)\nsp.playlist_add_items(last_playlist[\"items\"][0][\"id\"], mostOverlapsSongs[0:100])"
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#results",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#results",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "Results",
    "text": "Results\nThe script created a playlist with recommended songs from a given query; now what? We have to measure its performance. The performance of the model has to be obviously based on the number of liked new songs from the generated playlist. Therefore, higher the number of seed playlists higher the probability of catching a playlist with high overlap right? We set end_offset to 10000 and hit enter. However, this would be both time consuming (Runtime) and put a heavy load on the Spotify API; thus, runs the risk of being rate limited. I’ve imagined the scenario that if I were to use this algorithm in the production, what would be my KPI and have settled on Number of New Likes per Minute.\n\n\n\n\n\nThis graph shows New Likes and the Number of Seed Playlists in each experiment. All of the experiments used the same query for genre and I have listened to all of the songs in the playlists. While excluding the ones that are already in my library, I have counted the songs which I liked.\n\n\n\n\n\nThis figure, on the other hand, shows the Total Number of Songs in Each Playlist and our KPI or Number of New Likes per Minute which is calculated by dividing new likes by runtime.\nFrom both of the graphs, we can see that after 200 seed playlists, there are diminishing returns. New likes stays constant of and consequently, KPI decreases. One could argue that Experiment No. 2 has the highest KPI and therefore, it should be selected for the model. However, it generates low count of songs. I think a playlist with song count between 70 and 100 is better. Also greater seed has increased probability of finding more similar playlists."
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#discussion",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#discussion",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "Discussion",
    "text": "Discussion\nI think this was great learning experience for me and turned out nicer that I at first expected. Even though it doesn’t use any sophisticated algorithms, recommendations were mostly satisfying. It has to be said that the performance of my model depends a couple of variable, some of which I cannot control. For example, how much a user is invested in a genre is very important. If I have only 5 songs in my library for a target genre, my expectations would have to be low.\nThere three main controlling variables that changes the outcome of playlists: number of seed playlists, how many of the most overlapping playlists we take into consideration, and overlap threshold. They control how many songs will be in the generated playlist and a high overlap threshold tends to favor more popular songs, obviously. I manually tinkered with them to make song count between 70 and 100 in my experiments but in the future maybe I can add an automation of this. For now thanks for reading and see you next time!"
  },
  {
    "objectID": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#references",
    "href": "posts/find-relevant-music/2020-01-05-find-relevant-music.html#references",
    "title": "A Simple Way to Find Relevant Music on Spotify",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html",
    "href": "posts/book-forecasting/book_sales_forecasting.html",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "",
    "text": "Time to read: 10 minutes"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#arima",
    "href": "posts/book-forecasting/book_sales_forecasting.html#arima",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "ARIMA",
    "text": "ARIMA\nAutoregressive Integrated Moving Average (ARIMA) is a statistical method used for forecasting. It uses values at previous time points to predict current value (autoregression) and these regressions’ errors (moving average). Main assumption of ARIMA is that the time series should be stationary meaning its value is independent of time. Trend and seasonality makes the time series non-stationary. To make time series stationary we can use “differencing” - simply subtracting the value at t-1 from the value at t. “Integrated” part of the ARIMA is referring to the differencing order to make time series stationary.\nARIMA consists of three parts each having their own order - Autoregression p, Integration d, and Moving Average q. We will use Autocorrelation Function and Partial Autocorrelation Function graphs to select correct orders.\nMoving to our data, just by looking the above plots we can say there is a strong seasonality in the time series but to quantify it we will use Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test to check for stationarity.\n\nfrom statsmodels.tsa.stattools import kpss\n\nkpss_test = kpss(transformed_data)\nprint(f\"p-value of KPSS test is: {kpss_test[1]}\")\n\np-value of KPSS test is: 0.01\n\n\nNull hypothesis of KPSS test is that the series is stationary. Since the p-value of our test result is smaller that 0.05 we can reject the null hypothesis and state that the series is non-stationary.\nBefore creating the ARIMA model we have to remove trend and seasonality from the data. We could use the seasonal variant of ARIMA called SARIMA; however, our data’s frequency is a day so it has a periodicity of 365 days. SARIMA models are more suitable for monthly or quarterly data; therefore we will use Seasonal-Trend Decomposition Using LOESS (STL) method to remove trend and seasonality from the data.\n\nfrom statsmodels.tsa.seasonal import STL\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Setting plot style and size\nsns.set_style(\"darkgrid\")\nplt.rc(\"figure\", figsize=(7, 5))\nplt.rc(\"font\", size=10)\n\n# Create a sample subset to plot\nsubset = transformed_data.loc[\"Germany\", \"KaggleRama\", \"Kaggle Advanced Techniques\"]\n\n# Plot the decomposed parts of the time series\nstl = STL(subset, period=365, seasonal=7, trend_deg=1)\ndecomp = stl.fit()\nfig = decomp.plot()\nfig.show()\n\n/var/folders/p0/djprgmyj7hz8vjk9cjksykb00000gn/T/ipykernel_10420/2890160566.py:18: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n  fig.show()\n\n\n\n\n\nSTL Decomposition Results\n\n\n\n\nAbove code decomposed the subset time series to three parts: trend, season, and residuals. Before creating ARIMA model, we still have to make sure that the residual part is non-stationary. We will test for stationarity with KPSS again and use differencing until it is stationary. This differencing degree will determine our I(d) parameter in the ARIMA model.\n\ndiff_test = kpss(decomp.resid)\nprint(f\"p-value of KPSS test is: {diff_test[1]}\")\n\np-value of KPSS test is: 0.1\n\n\nResidual are stationary according to test so we won’t need a differencing in our model and therefore d degree will be 0. For the AR(p) order, we will look at the autocorrelation graphs. For the MA(q) order, we will try values and select the model with the lowest AIC (Akaike’s Information Criteria).\n\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nprint(plot_acf(decomp.resid))\nprint(plot_pacf(decomp.resid))\n\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/graphics/tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n  warnings.warn(\n\n\nFigure(672x480)\nFigure(672x480)\n\n\n\n\n\n\n\n\nPartial Autocorrelation Function shows statistically significant correlations at lags up to 7; thus we will start with AR(7). Now it is a good time to split our subset to train and test parts. Train data will be the first three years’ data and the test will be last year’s data.\n\nfrom statsmodels.tsa.forecasting.stl import STLForecast, STLForecastResults\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sktime.forecasting.model_selection import temporal_train_test_split\n\ntrain_subset, test_subset = temporal_train_test_split(subset, test_size=366)\n\n\nstl_forecast = STLForecast(train_subset,\n                    model=ARIMA,\n                    model_kwargs={\"order\": (7, 0, 0),\n                                  \"trend\": \"t\"},\n                    period=365,\n                    trend=1095,\n                    robust=False)\n\nmodel = stl_forecast.fit()\n# Forecast for the last year\nforecast = model.forecast(steps=366)\n# Plot both test data and forecast from the model to compare them visually.\nplot_series(test_subset, forecast, labels=[\"test_subset\", \"forecast\"])\nmodel.summary()\n\n\n\nSTL Decomposition and SARIMAX Results\n\n  Dep. Variable:           y          No. Observations:     1095   \n\n\n  Model:            ARIMA(7, 0, 0)    Log Likelihood      -3477.975\n\n\n  Date:            Sat, 10 Dec 2022   AIC                 6973.950 \n\n\n  Time:                18:04:15       BIC                 7018.937 \n\n\n  Sample:             01-01-2017      HQIC                6990.973 \n\n\n                     - 12-31-2019                                  \n\n\n  Covariance Type:        opg                                      \n\n\n\n\n            coef     std err      z      P>|z|  [0.025    0.975]  \n\n\n  x1         0.0074     0.135     0.055  0.956    -0.258     0.273\n\n\n  ar.L1      0.1083     0.019     5.696  0.000     0.071     0.146\n\n\n  ar.L2      0.1827     0.021     8.721  0.000     0.142     0.224\n\n\n  ar.L3      0.1113     0.018     6.122  0.000     0.076     0.147\n\n\n  ar.L4      0.1520     0.020     7.456  0.000     0.112     0.192\n\n\n  ar.L5      0.0204     0.020     1.024  0.306    -0.019     0.060\n\n\n  ar.L6     -0.0949     0.020    -4.857  0.000    -0.133    -0.057\n\n\n  ar.L7      0.5200     0.017    30.557  0.000     0.487     0.553\n\n\n  sigma2    33.3182     0.864    38.550  0.000    31.624    35.012\n\n\n\n\n  Ljung-Box (L1) (Q):     8.57   Jarque-Bera (JB):   629.83\n\n\n  Prob(Q):                0.00   Prob(JB):            0.00 \n\n\n  Heteroskedasticity (H): 1.06   Skew:                -0.10\n\n\n  Prob(H) (two-sided):    0.60   Kurtosis:            6.71 \n\n\n\nSTL Configuration\n\n  Period:                           365       Trend Length:                    1095\n\n\n  Seasonal:                           7       Trend deg:                          1\n\n\n  Seasonal deg:                       1       Trend jump:                         1\n\n\n  Seasonal jump:                      1       Low pass:                         367\n\n\n  Robust:                         False       Low pass deg:                       1\n\nWarnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\n\n\n\nThe forecast looks pretty good already; however, from the summary we detect that p-value for Ljung-Box test is smaller than 0.05. The null hypothesis of Ljung-Box test is that residuals of the model after fitting ARIMA is white noise and does not contain autocorrelations. Smaller than 0.05 p-value shows that our model could not capture the autocorrelations of the model fully. So will try different q orders and select the one which has the smallest AIC value and the case where the residuals are significantly autocorrelated (p > 0.05).\n\nq_orders = np.arange(0, 8)\nresults = []\nfor q in q_orders:\n    stl_forecast = STLForecast(train_subset,\n                    model=ARIMA,\n                    model_kwargs={\"order\": (7, 0, q),\n                                  \"trend\": \"t\"},\n                    period=365,\n                    trend=1095,\n                    robust=False)\n\n    model = stl_forecast.fit()\n    forecast = model.forecast(steps=366)\n    results.append(model.model_result.aic)\n\nprint(f\"Best q is {results.index(min(results))} with AIC value of {min(results)}\")\n\nBest q is 7 with AIC value of 6781.7431055363095\n\n\nLet’s check the summary again with q value of 7.\n\nstl_forecast = STLForecast(train_subset,\n                    model=ARIMA,\n                    model_kwargs={\"order\": (7, 0, 7),\n                                  \"trend\": \"t\"},\n                    period=365,\n                    trend=1095,\n                    robust=False)\n\nmodel = stl_forecast.fit()\n# Forecast for the last year\nforecast = model.forecast(steps=366)\n# Plot both test data and forecast from the model to compare them visually.\nplot_series(test_subset, forecast, labels=[\"test_subset\", \"forecast\"])\nmodel.summary()\n\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  self._init_dates(dates, freq)\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  self._init_dates(dates, freq)\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  self._init_dates(dates, freq)\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n  warn('Non-stationary starting autoregressive parameters'\n\n\n/Users/bertugmirasyedi/miniforge3/lib/python3.10/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\n\n\nSTL Decomposition and SARIMAX Results\n\n  Dep. Variable:           y          No. Observations:     1095   \n\n\n  Model:            ARIMA(7, 0, 7)    Log Likelihood      -3374.872\n\n\n  Date:            Sat, 10 Dec 2022   AIC                 6781.743 \n\n\n  Time:                18:04:27       BIC                 6861.719 \n\n\n  Sample:             01-01-2017      HQIC                6812.005 \n\n\n                     - 12-31-2019                                  \n\n\n  Covariance Type:        opg                                      \n\n\n\n\n            coef     std err      z      P>|z|  [0.025    0.975]  \n\n\n  x1         0.0307     0.042     0.725  0.468    -0.052     0.114\n\n\n  ar.L1     -0.5356     0.018   -29.124  0.000    -0.572    -0.500\n\n\n  ar.L2     -0.5941     0.025   -24.214  0.000    -0.642    -0.546\n\n\n  ar.L3     -0.2172     0.022    -9.847  0.000    -0.260    -0.174\n\n\n  ar.L4      0.3197     0.016    19.906  0.000     0.288     0.351\n\n\n  ar.L5      0.6246     0.022    28.755  0.000     0.582     0.667\n\n\n  ar.L6      0.4675     0.024    19.285  0.000     0.420     0.515\n\n\n  ar.L7      0.9349     0.018    52.310  0.000     0.900     0.970\n\n\n  ma.L1      0.8207     0.022    36.479  0.000     0.777     0.865\n\n\n  ma.L2      1.0375     0.034    30.775  0.000     0.971     1.104\n\n\n  ma.L3      0.7876     0.045    17.633  0.000     0.700     0.875\n\n\n  ma.L4      0.3276     0.046     7.110  0.000     0.237     0.418\n\n\n  ma.L5     -0.1245     0.040    -3.140  0.002    -0.202    -0.047\n\n\n  ma.L6     -0.1949     0.029    -6.761  0.000    -0.251    -0.138\n\n\n  ma.L7     -0.6672     0.021   -32.522  0.000    -0.707    -0.627\n\n\n  sigma2    27.4791     0.830    33.092  0.000    25.852    29.107\n\n\n\n\n  Ljung-Box (L1) (Q):     0.21   Jarque-Bera (JB):   359.53\n\n\n  Prob(Q):                0.65   Prob(JB):            0.00 \n\n\n  Heteroskedasticity (H): 1.08   Skew:                0.07 \n\n\n  Prob(H) (two-sided):    0.47   Kurtosis:            5.80 \n\n\n\nSTL Configuration\n\n  Period:                           365       Trend Length:                    1095\n\n\n  Seasonal:                           7       Trend deg:                          1\n\n\n  Seasonal deg:                       1       Trend jump:                         1\n\n\n  Seasonal jump:                      1       Low pass:                         367\n\n\n  Robust:                         False       Low pass deg:                       1\n\nWarnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\n\n\n\nFinally calculate the mean absolute percentage error (MAPE) as a benchmark.\n\nfrom sklearn.metrics import mean_absolute_percentage_error\n\nprint(f\"MAPE for STL-ARIMA model is: {mean_absolute_percentage_error(test_subset, forecast)}\")\n\nMAPE for STL-ARIMA model is: 0.18646794982275017"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#forecasting-with-exogenous-regressors",
    "href": "posts/book-forecasting/book_sales_forecasting.html#forecasting-with-exogenous-regressors",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "3.2 Forecasting with Exogenous Regressors",
    "text": "3.2 Forecasting with Exogenous Regressors\nNow we will move to the forecasting which uses exogenous variables as features. To achieve that, firstly, we will convert the datetime of the series to tabular features and then add holidays. We will also use some libraries dedicated to feature extraction from time series.\n\n3.2.1 ARIMAX\nFor ARIMAX model, we will create a feature_matrix which has the date related features and lagged values as predictors.\n\nimport featuretools as ft\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport holidays\nfrom statsmodels.tsa.deterministic import Fourier\n\n# First we will create an EntitySet\nentity_set = ft.EntitySet()\ndata = data.sort_values(by=[\"country\", \"store\", \"product\", \"date\"])\n\n# Specify index and time_index columns\nentity_set.add_dataframe(\n    dataframe_name=\"Datetime Features\",\n    dataframe=data,\n    index=\"row_id\",\n    time_index=\"date\",\n)\n\nfeature_matrix, feature_defs = ft.dfs(\n    entityset=entity_set,\n    target_dataframe_name=\"Datetime Features\",\n    trans_primitives=[\"DAY\", \"MONTH\", \"WEEKDAY\", \"YEAR\"],\n)\n\n# Label encode the year column\nyear_encoder = LabelEncoder()\nfeature_matrix[\"YEAR(date)\"] = year_encoder.fit_transform(feature_matrix[\"YEAR(date)\"])\n\n# Get the holidays for each country\nholidays_country = [holidays.country_holidays(i) for i in data[\"country\"].unique()]\n\n# Add the original date column for comparison\nfeature_matrix[\"date\"] = to_datetime(data[\"date\"])\n\n\n\"\"\"\nCheck dates for local holidays. \nIf there is a holiday on the date add their local name to holiday_name, else add \"No Holiday\".\n\"\"\"\nholiday_name = list()\nfor i in range(len(feature_matrix)):\n    if feature_matrix[\"country\"][i] == \"Belgium\":\n        if feature_matrix[\"date\"][i] in holidays_country[0]:\n            holiday_name.append(holidays_country[0].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n    elif feature_matrix[\"country\"][i] == \"France\":\n        if feature_matrix[\"date\"][i] in holidays_country[1]:\n            holiday_name.append(holidays_country[1].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n    elif feature_matrix[\"country\"][i] == \"Germany\":\n        if feature_matrix[\"date\"][i] in holidays_country[2]:\n            holiday_name.append(holidays_country[2].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n    elif feature_matrix[\"country\"][i] == \"Italy\":\n        if feature_matrix[\"date\"][i] in holidays_country[3]:\n            holiday_name.append(holidays_country[3].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n    elif feature_matrix[\"country\"][i] == \"Poland\":\n        if feature_matrix[\"date\"][i] in holidays_country[4]:\n            holiday_name.append(holidays_country[4].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n    elif feature_matrix[\"country\"][i] == \"Spain\":\n        if feature_matrix[\"date\"][i] in holidays_country[5]:\n            holiday_name.append(holidays_country[5].get(feature_matrix[\"date\"][i]))\n        else:\n            holiday_name.append(\"No Holiday\")\n\nfeature_matrix[\"HolidayName\"] = holiday_name\n\n# Sort the dataframe so that date is sequential\nfeature_matrix = feature_matrix.sort_values(\n    by=[\"country\", \"store\", \"product\", \"date\"], ignore_index=True\n)\n\n\"\"\"\nCheck for the closeness of days to holidays. If a day is in the spectrum of 3 days before -\n3 days after of a holiday, label it as Close.\n\"\"\"\nholiday_closeness = list()\nfor i in range(len(feature_matrix)):\n    if feature_matrix[\"HolidayName\"][i] != \"No Holiday\":\n        holiday_closeness.append(\"Holiday\")\n    else:\n        if len(list(\"No Holiday\" == feature_matrix[\"HolidayName\"][i - 3 : i + 4])) == 0:\n            holiday_closeness.append(\"Close\")\n        elif False in list(\n            \"No Holiday\" == feature_matrix[\"HolidayName\"][i - 3 : i + 4]\n        ):\n            holiday_closeness.append(\"Close\")\n        else:\n            holiday_closeness.append(\"Distant\")\nfeature_matrix[\"HolidayCloseness\"] = holiday_closeness\n\n# One-hot encode holiday closeness\nfeature_matrix = pandas.get_dummies(\n    feature_matrix,\n    columns=[\n        \"country\",\n        \"store\",\n        \"product\",\n        \"DAY(date)\",\n        \"MONTH(date)\",\n        \"WEEKDAY(date)\",\n        \"YEAR(date)\",\n        \"HolidayCloseness\",\n    ],\n    drop_first=True,\n)\n\n# Deterministic Fourier Terms\n## Yearly\nyearly_fourier_terms = Fourier(365, 3)\nindex = np.arange(0, 1461)\nyearly_fourier_terms = yearly_fourier_terms.in_sample(index)\ncloning_func = lambda x: np.tile(x, 48)\nyearly_fourier_terms = yearly_fourier_terms.apply(func=cloning_func, axis=0)\nfeature_matrix = feature_matrix.join(yearly_fourier_terms, how=\"left\")\n\n# Edit columns\nfeature_matrix = pandas.DataFrame.join(\n    feature_matrix.drop(columns=[\"num_sold\", \"HolidayName\"]),\n    feature_matrix[\"num_sold\"],\n    how=\"left\",\n)\n\nfeature_matrix\n\n\n\n\n\n  \n    \n      \n      date\n      country_France\n      country_Germany\n      country_Italy\n      country_Poland\n      country_Spain\n      store_KaggleRama\n      product_Kaggle Getting Started\n      product_Kaggle Recipe Book\n      product_Kaggle for Kids: One Smart Goose\n      ...\n      YEAR(date)_3\n      HolidayCloseness_Distant\n      HolidayCloseness_Holiday\n      sin(1,365)\n      cos(1,365)\n      sin(2,365)\n      cos(2,365)\n      sin(3,365)\n      cos(3,365)\n      num_sold\n    \n  \n  \n    \n      0\n      2017-01-01\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      1\n      0.000000e+00\n      1.000000\n      0.000000e+00\n      1.000000\n      0.000000e+00\n      1.000000\n      663\n    \n    \n      1\n      2017-01-02\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      1.721336e-02\n      0.999852\n      3.442161e-02\n      0.999407\n      5.161967e-02\n      0.998667\n      514\n    \n    \n      2\n      2017-01-03\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      3.442161e-02\n      0.999407\n      6.880243e-02\n      0.997630\n      1.031017e-01\n      0.994671\n      549\n    \n    \n      3\n      2017-01-04\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      5.161967e-02\n      0.998667\n      1.031017e-01\n      0.994671\n      1.543088e-01\n      0.988023\n      477\n    \n    \n      4\n      2017-01-05\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      1\n      0\n      6.880243e-02\n      0.997630\n      1.372788e-01\n      0.990532\n      2.051045e-01\n      0.978740\n      447\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      70123\n      2020-12-27\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      ...\n      1\n      0\n      0\n      -6.880243e-02\n      0.997630\n      -1.372788e-01\n      0.990532\n      -2.051045e-01\n      0.978740\n      204\n    \n    \n      70124\n      2020-12-28\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      ...\n      1\n      0\n      0\n      -5.161967e-02\n      0.998667\n      -1.031017e-01\n      0.994671\n      -1.543088e-01\n      0.988023\n      212\n    \n    \n      70125\n      2020-12-29\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      ...\n      1\n      1\n      0\n      -3.442161e-02\n      0.999407\n      -6.880243e-02\n      0.997630\n      -1.031017e-01\n      0.994671\n      242\n    \n    \n      70126\n      2020-12-30\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      ...\n      1\n      1\n      0\n      -1.721336e-02\n      0.999852\n      -3.442161e-02\n      0.999407\n      -5.161967e-02\n      0.998667\n      239\n    \n    \n      70127\n      2020-12-31\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      ...\n      1\n      1\n      0\n      -9.797174e-16\n      1.000000\n      -1.959435e-15\n      1.000000\n      -2.939152e-15\n      1.000000\n      202\n    \n  \n\n70128 rows × 69 columns\n\n\n\nThe feature matrix is almost ready for use in ARIMAX model. To summarize what we have done so far regarding the features, we have transformed the time points to categorical variables - day of the month, weekday, and year and added holidays. To better account for the effect of holidays, we have created three dummy holidays variables: Close, Distant and Holiday. Then to capture yearly seasonality we have added Fourier terms with period of 365. After creating the subset we can discard the country, product and store variables since we are training the models for each combination and they add nothing of value for forecasting in this case.\nLet’s create the ARIMAX model and forecast with the same subset.\n\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n# Create the same subset but this time with features.\nsubset_reg = feature_matrix[\n    (feature_matrix[\"country_Germany\"] == 1)\n    & (feature_matrix[\"store_KaggleRama\"] == 1)\n    & (feature_matrix[\"product_Kaggle Recipe Book\"] == 1)\n]\nsubset_reg = subset_reg.drop(\n    columns=[\n        \"date\",\n        \"country_France\",\n        \"country_Germany\",\n        \"country_Poland\",\n        \"country_Italy\",\n        \"country_Spain\",\n        \"store_KaggleRama\",\n        \"product_Kaggle Getting Started\",\n        \"product_Kaggle Recipe Book\",\n        \"product_Kaggle for Kids: One Smart Goose\",\n    ]\n)\n\n# Train - Test Split\ntrain_reg, test_reg = temporal_train_test_split(subset_reg, test_size=366)\n\n# Define endogenous and exogenous variables\nendog = train_reg[\"num_sold\"]\nexog = train_reg.drop(columns=\"num_sold\")\n\n# Use the same orders as previous ARIMA model\narimax_model = ARIMA(\n    order=(3, 1, 3), endog=endog, trend=[0, 1], exog=exog, enforce_stationarity=True\n)\n\narimax_results = arimax_model.fit()\n\n# Forecast for the last year\nforecast_reg = arimax_results.forecast(366, exog=test_reg.drop(columns=\"num_sold\"))\n\ntest_reg = test_reg.set_index(forecast_reg.index)\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(test_reg[\"num_sold\"], forecast_reg, title=\"ARIMAX Forecasts\");\n\n\n                                                \n\n\nFrom the plot we can see that this model performs worse than STL-ARIMA model. Let’s check ARIMAX model’s MAPE score to quantify performance difference.\n\n\nCode\nprint(f\"MAPE for ARIMAX model is: {mean_absolute_percentage_error(test_reg['num_sold'], forecast_reg)}\")\nprint(f\"R2 Score for ARIMAX model is: {r2_score(test_reg['num_sold'], forecast_reg)}\")\n\n\nMAPE for ARIMAX model is: 0.6281181684643169\nR2 Score for ARIMAX model is: -7.921475722370131\n\n\n\n\n3.2.2 XGBoost\nLet’s try the regression now with using XGBoost. We will again use the same feature matrix as exogenous variables but we’ll also use previous values of num_sold as input variables.\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Create a function so that we can try with different window sizes\ndef prev_values_tabularizer(feature_matrix, endog, window_size, scaler=False):\n    # Create a list to store previous values\n    prev_values = list()\n    for i in range(len(feature_matrix)):\n        prev_values.append(feature_matrix[endog][i : i + window_size])\n\n    # Reshape from columns to rows\n    prev_values = [\n        pandas.Series(prev_values[i]).values.reshape([1, -1])\n        for i in range(len(prev_values))\n    ]\n\n    # Create placeholder DataFrame with zeros and change them with previous values\n    zeros_matrix = np.zeros(shape=[len(feature_matrix), window_size])\n    placeholder_df = pandas.DataFrame(zeros_matrix)\n    for i in range(len(placeholder_df)):\n        for j in range(window_size):\n            try:\n                placeholder_df[j][i] = prev_values[i][0][j]\n            except IndexError:\n                continue\n\n    # Add previous values to feature matrix, shift it by window size, remove first window size values from the feature matrix\n    feature_matrix = pandas.concat([feature_matrix, placeholder_df], axis=1)\n    feature_matrix[list(range(window_size))] = feature_matrix[\n        list(range(window_size))\n    ].shift(window_size)\n    feature_matrix = feature_matrix.drop(list(range(window_size)), axis=0)\n\n    # If scaler is passed, apply scaling to previous values of endogenous variable\n    if scaler != False:\n        feature_matrix[list(range(window_size))] = scaler.fit_transform(\n            feature_matrix[list(range(window_size))]\n        )\n\n    # Reorder the columns so that endogenous variables are at the far most right\n    reordered_columns = (\n        feature_matrix.columns.to_list()[: (-window_size - 1)]\n        + feature_matrix.columns.to_list()[(-window_size):]\n        + [feature_matrix.columns.to_list()[(-window_size - 1)]]\n    )\n    feature_matrix = feature_matrix[reordered_columns]\n\n    return feature_matrix\n\n\nscaler = MinMaxScaler()\n\n# We use 7 as window_size because of the previous partial autocorrelation graphs\nregression_matrix = prev_values_tabularizer(feature_matrix, \"num_sold\", 7)\n\nWe have transformed the feature matrix suitable for forecasting with regression. Now we have to split it again to train and test subsets and create regression model with XGBoost.\n\nfrom xgboost import XGBRegressor\n\n# Create the same subset as previous examples and split\nsubset_xgboost = regression_matrix[\n    (regression_matrix[\"country_Germany\"] == 1)\n    & (regression_matrix[\"store_KaggleRama\"] == 1)\n    & (regression_matrix[\"product_Kaggle Recipe Book\"] == 1)\n]\nsubset_xgboost = subset_xgboost.drop(\n    columns=[\n        \"date\",\n        \"country_France\",\n        \"country_Germany\",\n        \"country_Poland\",\n        \"country_Italy\",\n        \"country_Spain\",\n        \"store_KaggleRama\",\n        \"product_Kaggle Getting Started\",\n        \"product_Kaggle Recipe Book\",\n        \"product_Kaggle for Kids: One Smart Goose\",\n    ]\n)\n\ntrain_subset_xgboost, test_subset_xgboost = temporal_train_test_split(\n    subset_xgboost, test_size=366\n)\n\n# Define train/test features and targets\ntrain_targets_xgboost = train_subset_xgboost[\"num_sold\"]\ntrain_features_xgboost = train_subset_xgboost.drop(columns=\"num_sold\")\ntest_targets_xgboost = test_subset_xgboost[\"num_sold\"]\ntest_features_xgboost = test_subset_xgboost.drop(columns=\"num_sold\")\n\n# Define model\nxgboost_model = XGBRegressor()\nxgboost_model.fit(train_features_xgboost, train_targets_xgboost)\n\n# Forecast for the last year\nforecast_xgboost = pandas.DataFrame(xgboost_model.predict(test_features_xgboost))\nforecast_xgboost.set_index(test_features_xgboost.index, inplace=True)\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(test_targets_xgboost, forecast_xgboost, title=\"XGBoost Forecasts\");\n\n\n                                                \n\n\nFrom the plot we can see that regression model with XGBoost performs better than ARIMAX model. Let’s check the scores again.\n\n\nCode\nprint(f\"MAPE for XGBoost Model is: {mean_absolute_percentage_error(test_targets_xgboost, forecast_xgboost)}\")\nprint(f\"R2 Score for XGBoost Model is: {r2_score(test_targets_xgboost, forecast_xgboost)}\")\n\n\nMAPE for XGBoost Model is: 0.09307335208975362\nR2 Score for XGBoost Model is: 0.6931165642563528\n\n\nScores surely seems better than our other forecasting attempts with STL-ARIMA and ARIMAX, though it can be said that this regression model tends not to undershoot. It is also more successful to capture New Year’s Eve sales than other models.\nIt is still early to call this the best model, since we didn’t tuned thoroughly the models’ hyperparamaters and there are deep learning models to try. Now we’ll move to the business case definition and after that, hyperparameter tuning of STL-ARIMA, ARIMAX, and XGBoost models. For deep learning part of this case please refer to Part 2."
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#deep-learning",
    "href": "posts/book-forecasting/book_sales_forecasting.html#deep-learning",
    "title": "Book Sales Forecasting: Comparison of Different Models",
    "section": "Deep Learning",
    "text": "Deep Learning\nNow we will create the forecasts with deep learning methods - LSTM and CNN. For these models we have to change feature and target DataFrames to Numpy arrays, and reshape features to 3 dimensional shape of (samples, timesteps, features). After creating a base model for both of them and comparing visually by plotting test features with forecasts, we will create our custom function in the next section and do hyperparameter tuning.\n\nLSTM\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Sequential\n\nwindow_size = 7\n\n# Create train and test data for LSTM\nlstm_train_features = np.array(train_features_sklearn)\nlstm_train_targets = np.array(train_targets_sklearn)\n\nlstm_test_features = np.array(test_features_sklearn)\nlstm_test_targets = np.array(test_targets_sklearn)\n\n# Reshape train and test features suitable fo RNN\nlstm_train_features = lstm_train_features.reshape((lstm_train_features.shape[0], 1, lstm_train_features.shape[1]))\n\nlstm_test_features = lstm_test_features.reshape((lstm_test_features.shape[0], 1, lstm_test_features.shape[1]))\n\n# Implement LSTM\nlstm_model = Sequential()\nlstm_model.add(layers.LSTM(50, activation=\"relu\"))\nlstm_model.add(layers.Dense(50, activation=\"relu\"))\nlstm_model.add(layers.Dense(1))\nlstm_model.compile(loss=\"mape\", optimizer=\"Adam\")\n\n# Fit and Forecast\nlstm_model.fit(lstm_train_features, lstm_train_targets, 1, 30)\nlstm_forecast = lstm_model.predict(lstm_test_features)\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_series(pandas.DataFrame(lstm_test_targets), pandas.DataFrame(lstm_forecast), labels=[\"test\", \"forecast\"])"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html",
    "href": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 2",
    "section": "",
    "text": "This post is the continuation of the book sales forecasting case. In this second part we will create deep learning models and hyperparameter tuning according to the assumed business case on Part 1."
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html#lstm",
    "href": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html#lstm",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 2",
    "section": "2.1 LSTM",
    "text": "2.1 LSTM\nFirstly, we will create a simple network.\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Sequential\n\n# Disable logging\ntf.keras.utils.disable_interactive_logging()\n\nwindow_size = 7\n\n# Create train and test data for LSTM\nlstm_train_features = np.array(train_features)\nlstm_train_targets = np.array(train_targets)\n\nlstm_test_features = np.array(test_features)\nlstm_test_targets = np.array(test_targets)\n\n# Reshape train and test features suitable fo RNN\nlstm_train_features = lstm_train_features.reshape((lstm_train_features.shape[0], 1, lstm_train_features.shape[1]))\n\nlstm_test_features = lstm_test_features.reshape((lstm_test_features.shape[0], 1, lstm_test_features.shape[1]))\n\n# Implement LSTM\nlstm_model = Sequential()\nlstm_model.add(layers.LSTM(50, activation=\"relu\"))\nlstm_model.add(layers.Dense(1))\nlstm_model.compile(loss=\"mape\", optimizer=\"Adam\")\n\n# Fit and Forecast\nlstm_model.fit(lstm_train_features, lstm_train_targets, 1, 5, verbose=0)\nlstm_forecast = lstm_model.predict(lstm_test_features)\n\n\n\nMetal device set to: Apple M1\nWARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n\n\n\n                                                \n\n\nFor easier comparison we will compute the previous benchmarks again.\n\n\nLSTM Benchmark Scores\nprint(f\"MAPE for LSTM model is: {mean_absolute_percentage_error(lstm_test_targets, lstm_forecast)}\")\nprint(f\"R2 Score for LSTM model is: {r2_score(lstm_test_targets, lstm_forecast)}\")\n\n\nMAPE for LSTM model is: 0.11236970126628876\nR2 Score for LSTM model is: 0.25165724866292205\n\n\nNow let’s create a simple CNN network and plot its forecasts."
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html#cnn",
    "href": "posts/book-forecasting/book_sales_forecasting_deep_learning_part.html#cnn",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 2",
    "section": "2.2 CNN",
    "text": "2.2 CNN\n\n\nSimple CNN Model\n# Disable logging\ntf.keras.utils.disable_interactive_logging()\n\n# Create train and test data for CNN\ncnn_train_features = np.array(train_features)\ncnn_train_targets = np.array(train_targets)\n\ncnn_test_features = np.array(test_features)\ncnn_test_targets = np.array(test_targets)\n\n# Reshape train and test features suitable fo RNN\ncnn_train_features = cnn_train_features.reshape((cnn_train_features.shape[0], 1, cnn_train_features.shape[1]))\ncnn_test_features = cnn_test_features.reshape((cnn_test_features.shape[0], 1, cnn_test_features.shape[1]))\n\n# Implement CNN\ncnn_model = Sequential()\ncnn_model.add(layers.Conv1D(50, 1, activation=\"relu\"))\ncnn_model.add(layers.Flatten())\ncnn_model.add(layers.Dense(1))\ncnn_model.compile(loss=\"mape\", optimizer=\"Adam\")\n\n# Fit and Forecast\ncnn_model.fit(cnn_train_features, cnn_train_targets, 1, 5, verbose=0);\ncnn_forecast = cnn_model.predict(cnn_test_features)\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(cnn_test_targets, cnn_forecast, title=\"Simple CNN Model Forecasts\");\n\n\n\n                                                \n\n\nPlots show comparable performances for simple LSTM and CNN models. Let’s quantify the comparison.\n\n\nMAPE for CNN model is: 0.10711897164583206\nR2 Score for CNN model is: 0.34101557513257685"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#stl-arima",
    "href": "posts/book-forecasting/book_sales_forecasting.html#stl-arima",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "3.1 STL-ARIMA",
    "text": "3.1 STL-ARIMA\nAutoregressive Integrated Moving Average (ARIMA) is a statistical method used for forecasting. It uses values at previous time points to predict current value (autoregression) and these regressions’ errors (moving average). Main assumption of ARIMA is that the time series should be stationary meaning its value is independent of time. Trend and seasonality makes the time series non-stationary. To make time series stationary we can use “differencing” - simply subtracting the value at t-1 from the value at t. “Integrated” part of the ARIMA is referring to the differencing order to make time series stationary.\nARIMA consists of three parts each having their own order - Autoregression p, Integration d, and Moving Average q. We will use Autocorrelation Function and Partial Autocorrelation Function graphs to select correct orders.\nMoving to our data, just by looking the above plots we can say there is a strong seasonality in the time series but to quantify it we will use Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test to check for stationarity.\n\nfrom statsmodels.tsa.stattools import kpss\n\nkpss_test = kpss(transformed_data)\nprint(f\"p-value of KPSS test is: {kpss_test[1]}\")\n\np-value of KPSS test is: 0.01\n\n\nNull hypothesis of KPSS test is that the series is stationary. Since the p-value of our test result is smaller that 0.05 we can reject the null hypothesis and state that the series is non-stationary.\nBefore creating the ARIMA model we have to remove trend and seasonality from the data. We could use the seasonal variant of ARIMA called SARIMA; however, our data’s frequency is a day so it has a periodicity of 365 days. SARIMA models are more suitable for monthly or quarterly data; therefore we will use Seasonal-Trend Decomposition Using LOESS (STL) method to remove trend and seasonality from the data.\n\nfrom statsmodels.tsa.seasonal import STL\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Setting plot style and size\nsns.set_style(\"darkgrid\")\nplt.rc(\"figure\", figsize=(7, 5))\nplt.rc(\"font\", size=10)\n\n# Create a sample subset to plot\nsubset = transformed_data.loc[\"Germany\", \"KaggleRama\", \"Kaggle Advanced Techniques\"]\n\n# Plot the decomposed parts of the time series\nstl = STL(subset, period=365, seasonal=7, trend_deg=1)\ndecomp = stl.fit()\nfig = decomp.plot()\nfig.show();\n\n\n\n\nSTL Decomposition Results\n\n\n\n\nAbove code decomposed the subset time series to three parts: trend, season, and residuals. Before creating ARIMA model, we still have to make sure that the residual part is non-stationary. We will test for stationarity with KPSS again and use differencing until it is stationary. This differencing degree will determine our I(d) parameter in the ARIMA model.\n\ndiff_test = kpss(decomp.resid)\nprint(f\"p-value of KPSS test is: {diff_test[1]}\")\n\np-value of KPSS test is: 0.1\n\n\nResidual are stationary according to test so we won’t need a differencing in our model and therefore d degree will be 0. For the AR(p) order, we will look at the autocorrelation graphs. For the MA(q) order, we will try values and select the model with the lowest AIC (Akaike’s Information Criteria).\n\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplot_acf(decomp.resid);\nplot_pacf(decomp.resid);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartial Autocorrelation Function shows statistically significant correlations at lags up to 7; thus we will start with AR(7). Now it is a good time to split our subset to train and test parts. Train data will be the first three years’ data and the test will be last year’s data.\n\nfrom statsmodels.tsa.forecasting.stl import STLForecast, STLForecastResults\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sktime.forecasting.model_selection import temporal_train_test_split\n\n# Split subset to train-test\ntrain_subset, test_subset_pretuning = temporal_train_test_split(subset, test_size=366)\n\n# Define STLForecast model\nstl_forecast = STLForecast(\n    train_subset,\n    model=ARIMA,\n    model_kwargs={\"order\": (7, 0, 0), \"trend\": \"t\"},\n    period=365,\n    trend=1095,\n    robust=False\n)\n\n# Fit the model\nmodel = stl_forecast.fit()\n\n# Forecast for the last year\nforecast = model.forecast(steps=366)\n\n# Create a function to plot both test data and forecast from the model to compare them visually.\ndef plot_forecasts(y_true, y_pred, title=\"Forecasts\", width=700, height=500):\n    # Create a DataFrame to store both series\n    series = pandas.DataFrame()\n    series[\"Observed\"] = y_true\n    series[\"Predicted\"] = y_pred\n    \n    # Define plot attributes\n    fig = px.line(\n        series, \n        width=width, \n        height=height, \n        title=title,\n        labels={\n            \"value\": \"Sales\",\n            \"variable\": \"\"\n        }\n    )\n    fig.show()\n\nplot_forecasts(test_subset_pretuning[\"num_sold\"], forecast, title=\"STL-ARIMA Forecasts with (7,0,0)\")\nmodel.summary()\n\n\n                                                \n\n\n\n\nSTL Decomposition and SARIMAX Results\n\n  Dep. Variable:           y          No. Observations:     1095   \n\n\n  Model:            ARIMA(7, 0, 0)    Log Likelihood      -3477.975\n\n\n  Date:            Sun, 18 Dec 2022   AIC                 6973.950 \n\n\n  Time:                12:13:26       BIC                 7018.937 \n\n\n  Sample:             01-01-2017      HQIC                6990.973 \n\n\n                     - 12-31-2019                                  \n\n\n  Covariance Type:        opg                                      \n\n\n\n\n            coef     std err      z      P>|z|  [0.025    0.975]  \n\n\n  x1         0.0074     0.135     0.055  0.956    -0.258     0.273\n\n\n  ar.L1      0.1083     0.019     5.696  0.000     0.071     0.146\n\n\n  ar.L2      0.1827     0.021     8.721  0.000     0.142     0.224\n\n\n  ar.L3      0.1113     0.018     6.122  0.000     0.076     0.147\n\n\n  ar.L4      0.1520     0.020     7.456  0.000     0.112     0.192\n\n\n  ar.L5      0.0204     0.020     1.024  0.306    -0.019     0.060\n\n\n  ar.L6     -0.0949     0.020    -4.857  0.000    -0.133    -0.057\n\n\n  ar.L7      0.5200     0.017    30.557  0.000     0.487     0.553\n\n\n  sigma2    33.3182     0.864    38.550  0.000    31.624    35.012\n\n\n\n\n  Ljung-Box (L1) (Q):     8.57   Jarque-Bera (JB):   629.83\n\n\n  Prob(Q):                0.00   Prob(JB):            0.00 \n\n\n  Heteroskedasticity (H): 1.06   Skew:                -0.10\n\n\n  Prob(H) (two-sided):    0.60   Kurtosis:            6.71 \n\n\n\nSTL Configuration\n\n  Period:                           365       Trend Length:                    1095\n\n\n  Seasonal:                           7       Trend deg:                          1\n\n\n  Seasonal deg:                       1       Trend jump:                         1\n\n\n  Seasonal jump:                      1       Low pass:                         367\n\n\n  Robust:                         False       Low pass deg:                       1\n\nWarnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\nThe forecast looks pretty good already; however, from the summary we detect that p-value for Ljung-Box test is smaller than 0.05. The null hypothesis of Ljung-Box test is that residuals of the model after fitting ARIMA does not contain autocorrelations. Smaller than 0.05 p-value shows that our model could not capture the autocorrelations of the model fully. So will try different q orders and select the one which has the smallest AIC value and the case where the residuals are significantly autocorrelated (p > 0.05).\n\nq_orders = np.arange(0, 8)\nresults = []\nfor q in q_orders:\n    stl_forecast = STLForecast(\n        train_subset,\n        model=ARIMA,\n        model_kwargs={\"order\": (7, 0, q), \"trend\": \"t\"},\n        period=365,\n        trend=1095,\n        robust=False,\n    )\n\n    model = stl_forecast.fit()\n    forecast = model.forecast(steps=366)\n    results.append(model.model_result.aic)\n\nprint(f\"Best q is {results.index(min(results))} with AIC value of {min(results)}\")\n\nBest q is 7 with AIC value of 6781.7431055363095\n\n\nLet’s check the summary again with q value of 7.\n\nstl_forecast = STLForecast(\n    train_subset,\n    model=ARIMA,\n    model_kwargs={\"order\": (7, 0, 7),\n                    \"trend\": \"t\"},\n    period=365,\n    trend=1095,\n    robust=False\n)\n\nmodel = stl_forecast.fit()\n\n# Forecast for the last year\nforecast = model.forecast(steps=366)\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(test_subset_pretuning[\"num_sold\"], forecast, title=\"STL-ARIMA Forecasts with (7,0,7)\")\n\nmodel.summary()\n\n\n                                                \n\n\n\n\nSTL Decomposition and SARIMAX Results\n\n  Dep. Variable:           y          No. Observations:     1095   \n\n\n  Model:            ARIMA(7, 0, 7)    Log Likelihood      -3374.872\n\n\n  Date:            Sun, 18 Dec 2022   AIC                 6781.743 \n\n\n  Time:                12:13:38       BIC                 6861.719 \n\n\n  Sample:             01-01-2017      HQIC                6812.005 \n\n\n                     - 12-31-2019                                  \n\n\n  Covariance Type:        opg                                      \n\n\n\n\n            coef     std err      z      P>|z|  [0.025    0.975]  \n\n\n  x1         0.0307     0.042     0.725  0.468    -0.052     0.114\n\n\n  ar.L1     -0.5356     0.018   -29.124  0.000    -0.572    -0.500\n\n\n  ar.L2     -0.5941     0.025   -24.214  0.000    -0.642    -0.546\n\n\n  ar.L3     -0.2172     0.022    -9.847  0.000    -0.260    -0.174\n\n\n  ar.L4      0.3197     0.016    19.906  0.000     0.288     0.351\n\n\n  ar.L5      0.6246     0.022    28.755  0.000     0.582     0.667\n\n\n  ar.L6      0.4675     0.024    19.285  0.000     0.420     0.515\n\n\n  ar.L7      0.9349     0.018    52.310  0.000     0.900     0.970\n\n\n  ma.L1      0.8207     0.022    36.479  0.000     0.777     0.865\n\n\n  ma.L2      1.0375     0.034    30.775  0.000     0.971     1.104\n\n\n  ma.L3      0.7876     0.045    17.633  0.000     0.700     0.875\n\n\n  ma.L4      0.3276     0.046     7.110  0.000     0.237     0.418\n\n\n  ma.L5     -0.1245     0.040    -3.140  0.002    -0.202    -0.047\n\n\n  ma.L6     -0.1949     0.029    -6.761  0.000    -0.251    -0.138\n\n\n  ma.L7     -0.6672     0.021   -32.522  0.000    -0.707    -0.627\n\n\n  sigma2    27.4791     0.830    33.092  0.000    25.852    29.107\n\n\n\n\n  Ljung-Box (L1) (Q):     0.21   Jarque-Bera (JB):   359.53\n\n\n  Prob(Q):                0.65   Prob(JB):            0.00 \n\n\n  Heteroskedasticity (H): 1.08   Skew:                0.07 \n\n\n  Prob(H) (two-sided):    0.47   Kurtosis:            5.80 \n\n\n\nSTL Configuration\n\n  Period:                           365       Trend Length:                    1095\n\n\n  Seasonal:                           7       Trend deg:                          1\n\n\n  Seasonal deg:                       1       Trend jump:                         1\n\n\n  Seasonal jump:                      1       Low pass:                         367\n\n\n  Robust:                         False       Low pass deg:                       1\n\nWarnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\nFinally calculate the mean absolute percentage error (MAPE) and R2 Score as a benchmark.\n\n\nCode\nfrom sklearn.metrics import mean_absolute_percentage_error, r2_score\n\nprint(f\"MAPE for STL-ARIMA model is: {mean_absolute_percentage_error(test_subset_pretuning, forecast)}\")\nprint(f\"R2 Score for STL-ARIMA model is: {r2_score(test_subset_pretuning, forecast)}\")\n\n\nMAPE for STL-ARIMA model is: 0.18646794982275017\nR2 Score for STL-ARIMA model is: -0.6091132358371121"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#stl-arima-tuning",
    "href": "posts/book-forecasting/book_sales_forecasting.html#stl-arima-tuning",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "5.1 STL-ARIMA Tuning",
    "text": "5.1 STL-ARIMA Tuning\n\nimport optuna\nimport statsmodels\n\n# Create validation data for STL-Arima\ntrain_subset = subset[\"num_sold\"][0:730].reset_index().drop(columns=\"index\")\ntest_subset = subset[\"num_sold\"][730:1095].reset_index().drop(columns=\"index\")\nval_subset = subset[\"num_sold\"][1095:1461].reset_index().drop(columns=\"index\")\n\n# Define Optuna Objective\ndef stl_objective(trial):\n\n    # Select ranges for p, d, q orders\n    p_order = trial.suggest_int(\"p_order\", 0, 10, log=False)\n    d_order = trial.suggest_int(\"d_order\", 0, 2, log=False)\n    q_order = trial.suggest_int(\"q_order\", 0, 10, log=False)\n    robust_bool = trial.suggest_categorical(\"robust_mode\", [False, True])\n    trend_deg = trial.suggest_int(\"trend_deg\", 0, 1)\n    seasonal_deg = trial.suggest_int(\"seasonal_deg\", 0, 1)\n    low_pass_deg = trial.suggest_int(\"low_pass_deg\", 0, 1)\n    seasonal_jump = trial.suggest_int(\"seasonal_jump\", 1, 3)\n    trend_jump = trial.suggest_int(\"trend_jump\", 1, 3)\n    low_pass_jump = trial.suggest_int(\"low_pass_jump\", 1, 3)\n\n    # Define model with trial variables\n    stl_forecast_tuned = STLForecast(\n        train_subset,\n        model=statsmodels.tsa.arima.model.ARIMA,\n        model_kwargs={\"order\": (p_order, d_order, q_order), \"trend\": \"n\"},\n        period=365,\n        trend=731,\n        trend_deg=trend_deg,\n        seasonal_deg=seasonal_deg,\n        low_pass_deg=low_pass_deg,\n        seasonal_jump=seasonal_jump,\n        trend_jump=trend_jump,\n        low_pass_jump=low_pass_jump,\n        robust=robust_bool,\n    )\n\n    # Fit and forecast test data\n    model = stl_forecast_tuned.fit()\n    forecast = model.forecast(steps=365)\n\n    # Reset index of forecasts\n    forecast = forecast.reset_index().drop(columns=\"index\")\n\n    # Create a loop to calculate cumulative cost of the forecast\n    storage = 0\n    cumulative_cost = 0\n    book_price = 20\n    monthly_storage_cost = 100\n    for step in range(len(test_subset)):\n\n        # Get the cost and difference for storage for the current step\n        cost, to_storage = cost_function(\n            storage, test_subset[\"num_sold\"][step], forecast[0][step], book_price, monthly_storage_cost\n        )\n\n        # Add cost to cumulative cost and storage difference to storage\n        cumulative_cost += int(cost)\n        storage += int(to_storage)\n\n    total_cost = cumulative_cost + storage * book_price\n    return total_cost\n\n\n# Create Optuna Study and Minimize total_cost\nstl_study = optuna.create_study(direction=\"minimize\")\nstl_study.optimize(stl_objective, n_trials=20)\n\nNow we’ll create the model with best parameters to get tuned forecasts.\n\n# Get the parameters of the best model\nbest_stl_model_parameters = stl_study.best_params\n\n# Define STL-Arima model with the best parameters and train on test data\nstl_forecast = STLForecast(\n    test_subset,\n    model=statsmodels.tsa.arima.model.ARIMA,\n    model_kwargs={\n        \"order\": (\n            best_stl_model_parameters[\"p_order\"],\n            best_stl_model_parameters[\"d_order\"],\n            best_stl_model_parameters[\"q_order\"],\n        ),\n        \"trend\": \"n\",\n    },\n    period=365,\n    trend=1095,\n    robust=best_stl_model_parameters[\"robust_mode\"],\n    trend_deg=best_stl_model_parameters[\"trend_deg\"],\n    seasonal_deg=best_stl_model_parameters[\"seasonal_deg\"],\n    low_pass_deg=best_stl_model_parameters[\"low_pass_deg\"],\n    seasonal_jump=best_stl_model_parameters[\"seasonal_jump\"],\n    trend_jump=best_stl_model_parameters[\"trend_jump\"],\n    low_pass_jump=best_stl_model_parameters[\"low_pass_jump\"],\n)\n\n# Fit and forecast test data\ntuned_stl_model = stl_forecast.fit()\nforecast_stl_arima_tuned = tuned_stl_model.forecast(steps=366)\nforecast_stl_arima_tuned = forecast_stl_arima_tuned.reset_index().drop(columns=\"index\")\n\n# Create a loop to calculate cumulative cost of the forecast\nstorage = 0\ncumulative_cost = 0\nbook_price = 20\nmonthly_storage_cost = 100\nfor step in range(len(val_subset)):\n\n    # Get the cost and difference for storage for the current step\n    cost, to_storage = cost_function(\n        storage,\n        val_subset[\"num_sold\"][step],\n        forecast_stl_arima_tuned[0][step],\n        book_price,\n        monthly_storage_cost,\n    )\n\n    # Add cost to cumulative cost and storage difference to storage\n    cumulative_cost += int(cost)\n    storage += int(to_storage)\n\nstl_arima_total_cost = cumulative_cost + storage * book_price\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(val_subset, forecast_stl_arima_tuned, title=\"STL ARIMA Tuned Forecasts\");\n\n\n                                                \n\n\nCalculate the MAPE and R2 Scores and the total cost according to our metric.\n\n\nCode\nprint(f\"MAPE for Earlier STL-ARIMA Model is: {mean_absolute_percentage_error(test_subset_pretuning, forecast)}\")\nprint(f\"MAPE for Tuned STL-ARIMA is: {mean_absolute_percentage_error(val_subset['num_sold'], forecast_stl_arima_tuned[0])}\\n\")\nprint(f\"R2 Score for Earlier STL-ARIMA Model is: {r2_score(test_subset_pretuning, forecast)}\")\nprint(f\"R2 Score for Tuned STL-ARIMA is: {r2_score(val_subset['num_sold'], forecast_stl_arima_tuned[0])}\\n\")\n\nprint(f\"Total Cost for tuned STL-ARIMA is: €{stl_arima_total_cost:,.2f}\")\n\n\nMAPE for Earlier STL-ARIMA Model is: 0.18646794982275017\nMAPE for Tuned STL-ARIMA is: 0.1666647758683933\n\nR2 Score for Earlier STL-ARIMA Model is: -0.6091132358371121\nR2 Score for Tuned STL-ARIMA is: 0.03715486112144273\n\nTotal Cost for tuned STL-ARIMA is: €72,474.00"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#arimax-tuning",
    "href": "posts/book-forecasting/book_sales_forecasting.html#arimax-tuning",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "5.2 ARIMAX Tuning",
    "text": "5.2 ARIMAX Tuning\n\n\nOptuna ARIMAX Tuning Code\n# Create validation data for ARIMAX\ntrain_subset = subset[0:730]\ntest_subset = subset[730:1095]\nval_subset = subset[1095:1461]\n\n# Define endogenous and exogenous variables\ntrain_targets = pandas.DataFrame(train_subset[\"num_sold\"]).reset_index().drop(columns=\"index\")\ntrain_features = pandas.DataFrame(train_subset.drop(columns=\"num_sold\")).reset_index().drop(columns=\"index\")\n\ntest_targets = pandas.DataFrame(test_subset[\"num_sold\"]).reset_index().drop(columns=\"index\")\ntest_features = pandas.DataFrame(test_subset.drop(columns=\"num_sold\")).reset_index().drop(columns=\"index\")\n\nval_targets = pandas.DataFrame(val_subset[\"num_sold\"]).reset_index().drop(columns=\"index\")\nval_features = pandas.DataFrame(val_subset.drop(columns=\"num_sold\")).reset_index().drop(columns=\"index\")\n\n# Define Optuna Objective\ndef arimax_objective(trial):\n\n  # Select ranges for p, d, q orders\n  p_order = trial.suggest_int(\"p_order\", 0, 10, log=False)\n  d_order = trial.suggest_int(\"d_order\", 0, 2, log=False)\n  q_order = trial.suggest_int(\"q_order\", 0, 10, log=False)\n\n  # Trend order according to d_order differencing\n  trend_order = list(np.zeros(d_order))\n  trend_order.append(1)\n\n  # Define model with trial variables\n  arimax_model = statsmodels.tsa.arima.model.ARIMA(\n    order=(p_order, d_order, q_order),\n    endog=train_targets,\n    trend=trend_order,\n    exog=train_features\n  )\n  \n  # Fit the model\n  arimax_model_results = arimax_model.fit()\n\n  # Forecast for the last year\n  forecast_arimax_tuned = arimax_model_results.forecast(365, exog=test_features)\n  forecast_arimax_tuned = pandas.DataFrame(forecast_arimax_tuned).reset_index().drop(columns=\"index\")\n\n  # Create a loop to calculate cumulative cost of the forecast\n  storage = 0\n  cumulative_cost = 0\n  book_price = 20\n  monthly_storage_cost = 100\n  for step in range(len(test_targets)):\n\n    # Get the cost and difference for storage for the current step\n    cost, to_storage = cost_function(\n      storage, \n      test_targets[\"num_sold\"][step], \n      forecast_arimax_tuned[\"predicted_mean\"][step], \n      book_price, \n      monthly_storage_cost\n      )\n\n    # Add cost to cumulative cost and storage difference to storage\n    cumulative_cost += int(cost)\n    storage += int(to_storage)\n\n  total_cost = cumulative_cost + storage*book_price\n  return total_cost\n\n# Create Optuna Study and Minimize total_cost\narimax_study = optuna.create_study(direction=\"minimize\")\narimax_study.optimize(arimax_objective, n_trials=20)\n\n\n\n\nForecasts with Best ARIMAX Parameters Code\n# Get the parameters of the best model\nbest_arimax_model_parameters = arimax_study.best_params\n\n# Trend order according to d_order differencing\ntrend_order = list(np.zeros(best_arimax_model_parameters[\"d_order\"]))\ntrend_order.append(1)\n\n# Define Arimax model with the best parameters and train on test data\narimax_model = statsmodels.tsa.arima.model.ARIMA(\n  order=(best_arimax_model_parameters[\"p_order\"],\n  best_arimax_model_parameters[\"d_order\"],\n  best_arimax_model_parameters[\"q_order\"]),\n  endog=test_targets,\n  trend=[0],\n  exog=test_features)\n\n# Fit the model\narimax_model_results = arimax_model.fit()\n\n# Forecast for the last year\nforecast_arimax_tuned = arimax_model_results.forecast(366, exog=val_features)\nforecast_arimax_tuned = pandas.DataFrame(forecast_arimax_tuned).reset_index().drop(columns=\"index\")\n\n# Create a loop to calculate cumulative cost of the forecast\nstorage = 0\ncumulative_cost = 0\nbook_price = 20\nmonthly_storage_cost = 100\nfor step in range(len(val_targets)):\n\n  # Get the cost and difference for storage for the current step\n  cost, to_storage = cost_function(\n    storage, \n    val_targets[\"num_sold\"][step], \n    forecast_arimax_tuned[\"predicted_mean\"][step], \n    book_price, \n    monthly_storage_cost)\n\n  # Add cost to cumulative cost and storage difference to storage\n  cumulative_cost += int(cost)\n  storage += int(to_storage)\n\narimax_total_cost = cumulative_cost + storage*book_price\n\n# Plot both test data and forecast from the model to compare them visually.\nplot_forecasts(val_targets, forecast_arimax_tuned, title=\"ARIMAX Tuned Forecasts\");\n\n\n\n                                                \n\n\n\n\nCode\nprint(f\"MAPE for Earlier ARIMAX model is: {mean_absolute_percentage_error(test_reg['num_sold'], forecast_reg)}\")\nprint(f\"MAPE for Tuned ARIMAX model is: {mean_absolute_percentage_error(val_targets['num_sold'], forecast_arimax_tuned['predicted_mean'])}\\n\")\n\nprint(f\"R2 Score for Earlier ARIMAX model is: {r2_score(test_reg['num_sold'], forecast_reg)}\")\nprint(f\"R2 Score for Tuned ARIMAX model is: {r2_score(val_targets['num_sold'], forecast_arimax_tuned['predicted_mean'])}\\n\")\n\nprint(f\"Total Cost for tuned ARIMAX model is: €{arimax_total_cost:,.2f}\")\n\n\nMAPE for Earlier ARIMAX model is: 0.6281181684643169\nMAPE for Tuned ARIMAX model is: 0.9091655799646171\n\nR2 Score for Earlier ARIMAX model is: -7.921475722370131\nR2 Score for Tuned ARIMAX model is: -18.59284765359555\n\nTotal Cost for tuned ARIMAX model is: €505,022.00"
  },
  {
    "objectID": "posts/book-forecasting/book_sales_forecasting.html#xgboost-tuning",
    "href": "posts/book-forecasting/book_sales_forecasting.html#xgboost-tuning",
    "title": "Book Sales Forecasting: Comparison of Different Models Part 1",
    "section": "5.3 XGBoost Tuning",
    "text": "5.3 XGBoost Tuning\n\n\nXGBoost Optuna Tuning and regression_forecast Function\nfrom xgboost import XGBRegressor\n\n# Create train - test- validation data\nsubset_xgboost_tuned = regression_matrix[\n    (regression_matrix[\"country_Germany\"] == 1)\n    & (regression_matrix[\"store_KaggleRama\"] == 1)\n    & (regression_matrix[\"product_Kaggle Recipe Book\"] == 1)\n]\nsubset_xgboost_tuned = subset_xgboost_tuned.drop(\n    columns=[\n        \"date\",\n        \"country_France\",\n        \"country_Germany\",\n        \"country_Poland\",\n        \"country_Italy\",\n        \"country_Spain\",\n        \"store_KaggleRama\",\n        \"product_Kaggle Getting Started\",\n        \"product_Kaggle Recipe Book\",\n        \"product_Kaggle for Kids: One Smart Goose\",\n    ]\n)\n\n# Define train - test - validation features and targets\ntrain_subset_xgboost_tuned, test_subset_xgboost_tuned = temporal_train_test_split(\n    subset_xgboost_tuned, train_size=730\n)\ntest_subset_xgboost_tuned, val_subset_xgboost_tuned = temporal_train_test_split(\n    test_subset_xgboost_tuned, test_size=366\n)\n\ntrain_targets_xgboost_tuned = (\n    pandas.DataFrame(train_subset_xgboost_tuned[\"num_sold\"])\n    .reset_index()\n    .drop(columns=\"index\")\n)\ntrain_features_xgboost_tuned = (\n    pandas.DataFrame(train_subset_xgboost_tuned.drop(columns=\"num_sold\"))\n    .reset_index()\n    .drop(columns=\"index\")\n)\n\ntest_targets_xgboost_tuned = (\n    pandas.DataFrame(test_subset_xgboost_tuned[\"num_sold\"])\n    .reset_index()\n    .drop(columns=\"index\")\n)\ntest_features_xgboost_tuned = (\n    pandas.DataFrame(test_subset_xgboost_tuned.drop(columns=\"num_sold\"))\n    .reset_index()\n    .drop(columns=\"index\")\n)\n\nval_targets_xgboost_tuned = (\n    pandas.DataFrame(val_subset_xgboost_tuned[\"num_sold\"])\n    .reset_index()\n    .drop(columns=\"index\")\n)\nval_features_xgboost_tuned = (\n    pandas.DataFrame(val_subset_xgboost_tuned.drop(columns=\"num_sold\"))\n    .reset_index()\n    .drop(columns=\"index\")\n)\n\n# Define forecasting function\ndef regression_forecast(\n    train_features, forecast_features, model, window_size, scaled=False\n):\n\n    # Add the last column of training data\n    history = train_features.tail(1)\n    forecasts = list()\n    for _ in range(len(forecast_features)):\n        prediction = model.predict(history.tail(1))\n\n        # Get features of data to be forecasted\n        next_sample = forecast_features.head(1)\n\n        # Shift previous values to 1 left\n        next_sample[list(range(window_size))] = (\n            history.tail(1)[list(range(window_size))].shift(-1, axis=1).values\n        )\n\n        # If scaled, inverse transform\n        if scaled != False:\n            next_sample[list(range(window_size))] = scaler.inverse_transform(\n                next_sample[list(range(window_size))]\n            )\n\n            # Add prediction to the right\n            next_sample[window_size - 1] = prediction\n\n            # Scale values again before forecasting\n            next_sample[list(range(window_size))] = scaler.transform(\n                next_sample[list(range(window_size))]\n            )\n        else:\n            # Add prediction to the right\n            next_sample[window_size - 1] = prediction\n\n        # Add last values to history\n        history = pandas.concat([history, next_sample], ignore_index=True, axis=0)\n\n        # Drop uppermost row from forecast features\n        forecast_features = forecast_features.drop(index=min(forecast_features.index))\n\n        # Add current prediction the forecasts as a seperate list\n        forecasts.append(prediction)\n\n    return pandas.DataFrame(forecasts, columns=[\"prediction\"])\n\n\n# Define Optuna Objective\ndef xgboost_objective(trial):\n\n    # Define trial variables\n    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n\n    if booster in [\"gbtree\", \"dart\"]:\n        eta = trial.suggest_float(\"eta\", 0, 1)\n        gamma = trial.suggest_int(\"gamma\", 0, 2)\n        max_depth = trial.suggest_int(\"max_depth\", 1, 50)\n        min_child_weight = trial.suggest_int(\"min_child_weight\", 0, 20)\n        subsample = trial.suggest_float(\"subsample\", 0.5, 1)\n        reg_lambda = trial.suggest_float(\"lambda\", 0, 5)\n        alpha = trial.suggest_float(\"alpha\", 0, 5)\n\n        # Define model with trial variables\n        xgboost_model = XGBRegressor(\n            booster=booster,\n            learning_rate=eta,\n            min_split_loss=gamma,\n            max_depth=max_depth,\n            min_child_weight=min_child_weight,\n            subsample=subsample,\n            reg_lambda=reg_lambda,\n            reg_alpha=alpha,\n        )\n    else:\n        reg_lambda = trial.suggest_float(\"lambda\", 0, 5)\n        alpha = trial.suggest_float(\"alpha\", 0, 5)\n        updater = trial.suggest_categorical(\"updater\", [\"shotgun\", \"coord_descent\"])\n        feature_selector = trial.suggest_categorical(\n            \"feature_selector\", [\"cyclic\", \"shuffle\"]\n        )\n\n        # Define model with trial variables\n        xgboost_model = XGBRegressor(\n            booster=booster,\n            reg_lambda=reg_lambda,\n            reg_alpha=alpha,\n            updater=updater,\n            feature_selector=feature_selector,\n        )\n\n    # Fit the model\n    xgboost_model.fit(train_features_xgboost_tuned, train_targets_xgboost_tuned)\n\n    # Forecast for the test data but this time using model's predicted values as past values\n    forecast_xgboost_tuned = regression_forecast(\n        train_features_xgboost_tuned, \n        test_features_xgboost_tuned, \n        xgboost_model, \n        7\n    )\n\n    # Create a loop to calculate cumulative cost of the forecast\n    storage = 0\n    cumulative_cost = 0\n    book_price = 20\n    monthly_storage_cost = 100\n    for step in range(len(test_targets_xgboost_tuned)):\n\n        # Get the cost and difference for storage for the current step\n        cost, to_storage = cost_function(\n            storage,\n            test_targets_xgboost_tuned[\"num_sold\"][step],\n            forecast_xgboost_tuned[\"prediction\"][step],\n            book_price,\n            monthly_storage_cost,\n        )\n\n        # Add cost to cumulative cost and storage difference to storage\n        cumulative_cost += int(cost)\n        storage += int(to_storage)\n\n    total_cost = cumulative_cost + storage * book_price\n    return total_cost\n\n\n# Create Optuna Study and Minimize total_cost\nxgboost_study = optuna.create_study(direction=\"minimize\")\nxgboost_study.optimize(xgboost_objective, n_trials=20)\n\n\n\n\nXGBoost Model with Best Parameters Code\nbest_xgboost_model_parameters = xgboost_study.best_params\n\nif best_xgboost_model_parameters[\"booster\"] in [\"gbtree\", \"dart\"]:\n    # Define model with trial variables\n    xgboost_model = XGBRegressor(\n        booster=best_xgboost_model_parameters[\"booster\"],\n        learning_rate=best_xgboost_model_parameters[\"eta\"],\n        min_split_loss=best_xgboost_model_parameters[\"gamma\"],\n        max_depth=best_xgboost_model_parameters[\"max_depth\"],\n        min_child_weight=best_xgboost_model_parameters[\"min_child_weight\"],\n        subsample=best_xgboost_model_parameters[\"subsample\"],\n        reg_lambda=best_xgboost_model_parameters[\"lambda\"],\n        reg_alpha=best_xgboost_model_parameters[\"alpha\"]\n    )\nelse:\n    # Define model with trial variables\n    xgboost_model = XGBRegressor(\n        booster=best_xgboost_model_parameters[\"booster\"],\n        reg_lambda=best_xgboost_model_parameters[\"lambda\"],\n        reg_alpha=best_xgboost_model_parameters[\"alpha\"],\n        updater=best_xgboost_model_parameters[\"updater\"],\n        feature_selector=best_xgboost_model_parameters[\"feature_selector\"]\n    )\n\n# Fit the model with the best parameters\nxgboost_model.fit(test_features_xgboost_tuned, test_targets_xgboost_tuned)\n\n# Forecast for the test data but this time using model's predicted values as past values\nforecast_xgboost_tuned = regression_forecast(\n  test_features_xgboost_tuned,\n  val_features_xgboost_tuned,\n  xgboost_model,\n  7)\n\n# Create a loop to calculate cumulative cost of the forecast\nstorage = 0\ncumulative_cost = 0\nbook_price = 20\nmonthly_storage_cost = 100\nfor step in range(len(val_targets_xgboost_tuned)):\n\n    # Get the cost and difference for storage for the current step\n    cost, to_storage = cost_function(\n      storage, \n      val_targets_xgboost_tuned[\"num_sold\"][step], \n      forecast_xgboost_tuned[\"prediction\"][step], \n      book_price, \n      monthly_storage_cost)\n\n    # Add cost to cumulative cost and storage difference to storage\n    cumulative_cost += int(cost)\n    storage += int(to_storage)\n\nxgboost_total_cost = cumulative_cost + storage*book_price\n\n# Plot the forecasts compared to validation data\nplot_forecasts(val_targets_xgboost_tuned, forecast_xgboost_tuned, title=\"XGBoost Tuned Forecasts\");\n\n\n\n                                                \n\n\n\n\nCode\nprint(f\"MAPE for Earlier XGBoost model is: {mean_absolute_percentage_error(test_targets_xgboost, forecast_xgboost)}\")\nprint(f\"MAPE for Tuned XGBoost model is: {mean_absolute_percentage_error(val_targets_xgboost_tuned, forecast_xgboost_tuned)}\\n\")\n\nprint(f\"R2 Score for Earlier XGBoost model is: {mean_absolute_percentage_error(test_targets_xgboost, forecast_xgboost)}\")\nprint(f\"R2 Score for Tuned XGBoost model is: {r2_score(val_targets_xgboost_tuned, forecast_xgboost_tuned)}\\n\")\n\nprint(f\"Total Cost for Tuned XGBoost model is: €{xgboost_total_cost:,.2f}\")\n\n\nMAPE for Earlier XGBoost model is: 0.09307335208975362\nMAPE for Tuned XGBoost model is: 0.1667327819877228\n\nR2 Score for Earlier XGBoost model is: 0.09307335208975362\nR2 Score for Tuned XGBoost model is: 0.05834389322854061\n\nTotal Cost for Tuned XGBoost model is: €64,838.00\n\n\nTuning for XGBoost model loses some accuracy due to the difference between lagged value features. Earlier model was using real targets as lagged value, while this tuned and correct model uses its own forecasts as lagged values. We’ll create and tune deep learning models on\n\n\nPart 2 ->"
  }
]